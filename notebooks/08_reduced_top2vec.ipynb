{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reduced Top2Vec Training",
   "id": "f6d390d739ad4636"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependencies",
   "id": "e0cfbfcf9cdcdda1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "from top2vec import Top2Vec\n",
    "from gensim import corpora, models\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "13382b07479346c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Dataset",
   "id": "bd65eaf9a7289530"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load Processed Data\n",
    "df = pd.read_csv(\"../data/processed/20250515_1207_minimal_clean_merged_tweets.csv\")\n",
    "df.info()"
   ],
   "id": "ae865cc9052e56ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation",
   "id": "cd190b407c8ddb77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CONFIGURATION FOR SAVING\n",
    "model_name = 'TOP2VEC_reduced'\n",
    "\n",
    "# Get today's date in YYYYMMDD format\n",
    "date_today = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Saved dir path\n",
    "results_dir = f\"../results/{date_today}_{model_name}\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "TOP_DIVERSITY_WORDS_N = 30\n",
    "TOP_COHERENCE_WORDS_N = 10\n",
    "\n",
    "model_path = f\"../results/{date_today}_TOP2VEC/top2vec_model_{date_today}.model\"\n",
    "top2vec_model = Top2Vec.load(model_path)\n",
    "\n",
    "# Tokenization\n",
    "documents = df['final_text'].astype(str).tolist()\n",
    "tokenized_texts = [str(doc).split() for doc in documents]\n",
    "dictionary = corpora.Dictionary(tokenized_texts)"
   ],
   "id": "1c73e82420f873a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Custom Diversity Score Function",
   "id": "5125b99981fdf19f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_topic_diversity_from_topics(topics_words, top_n=10):\n",
    "    all_words = []\n",
    "    for topic in topics_words:\n",
    "        all_words.extend(topic[:top_n])\n",
    "    unique_words = set(all_words)\n",
    "    diversity_score = len(unique_words) / len(all_words)\n",
    "    return diversity_score"
   ],
   "id": "64cf86db430fa9ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Main Reduce Topic Function",
   "id": "5950705296e896ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for num_topics_target in range(100, 24, -25):\n",
    "    print(f\"Reduced to {num_topics_target} topics\")\n",
    "\n",
    "    # Reduce prev model\n",
    "    top2vec_model.hierarchical_topic_reduction(num_topics=num_topics_target)\n",
    "\n",
    "    # Get only reduced topics\n",
    "    topics_words, _, _ = top2vec_model.get_topics()\n",
    "    topics_words = topics_words[:num_topics_target]\n",
    "\n",
    "    # Prepare topic_words_list for coherence calculation\n",
    "    topic_words_list = [topic[:TOP_DIVERSITY_WORDS_N] for topic in topics_words]\n",
    "\n",
    "    # Now save topic-word list properly\n",
    "    topic_word_list = []\n",
    "    for i, word_list in enumerate(topics_words):\n",
    "        for word in word_list[:TOP_DIVERSITY_WORDS_N]:\n",
    "            topic_word_list.append({\n",
    "                \"topic\": i,\n",
    "                \"word\": word\n",
    "            })\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model = models.CoherenceModel(\n",
    "        topics=topic_words_list,\n",
    "        texts=tokenized_texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v',\n",
    "        topn=TOP_COHERENCE_WORDS_N,\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "    print(f\"Final Top2Vec model coherence (c_v): {coherence_score:.4f}\")\n",
    "\n",
    "    # Compute Topic Diversity Scores\n",
    "    top_n_values = [5, 10, 20, 30]\n",
    "    diversity_score_results = []\n",
    "    for top_n in top_n_values:\n",
    "        diversity_score = compute_topic_diversity_from_topics(topics_words, top_n=top_n)\n",
    "        diversity_score_results.append({\"top_n\": top_n, \"topic_diversity\": diversity_score})\n",
    "        print(f\"top_n: {top_n} topic_diversity: {diversity_score}\")\n",
    "\n",
    "    # Save diversity scores\n",
    "    df_diversity = pd.DataFrame(diversity_score_results)\n",
    "    df_diversity.to_csv(os.path.join(results_dir, f\"diversity_scores_reduced_{num_topics_target}_top2vec_topic_{date_today}.csv\"), index=False)\n",
    "\n",
    "    # Save topic-word distributions\n",
    "    topic_word_list = []\n",
    "    for i, topic_words in enumerate(topics_words):\n",
    "        for word in topic_words[:TOP_DIVERSITY_WORDS_N]:\n",
    "            topic_word_list.append({\n",
    "                \"topic\": i,\n",
    "                \"word\": word\n",
    "            })\n",
    "    df_topics = pd.DataFrame(topic_word_list)\n",
    "    df_topics.to_csv(os.path.join(results_dir, f\"topic_word_distributions_reduced_{num_topics_target}_top2vec_{date_today}.csv\"), index=False)\n",
    "\n",
    "    # Save model\n",
    "    top2vec_model.save(os.path.join(results_dir, f\"model_reduced_{num_topics_target}_top2vec_{date_today}.model\"))\n",
    "\n",
    "    # Save Summary\n",
    "    summary = {\n",
    "        \"coherence_score\": coherence_score,\n",
    "        \"dictionary_size\": len(dictionary),\n",
    "        \"num_documents\": len(documents),\n",
    "        \"num_topics\": len(topics_words),\n",
    "    }\n",
    "    for row in diversity_score_results:\n",
    "        summary[f\"diversity_score_top{row['top_n']}\"] = row[\"topic_diversity\"]\n",
    "\n",
    "    pd.DataFrame([summary]).to_csv(os.path.join(results_dir, f\"scores_model_summary_reduced_{num_topics_target}_top2vec_{date_today}.csv\"), index=False)\n",
    "\n",
    "    print(f\"Final Reduced Top2Vec to {num_topics_target} topic model, topics, and summaries saved to: {results_dir}\")\n",
    "\n",
    "    # Build structured list\n",
    "    topic_word_data = []\n",
    "    for topic_num, word_list in enumerate(topics_words):\n",
    "        for rank, word in enumerate(word_list, start=1):\n",
    "            topic_word_data.append({\n",
    "                \"topic\": topic_num,\n",
    "                \"word_rank\": rank,\n",
    "                \"word\": word,\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_topic_words = pd.DataFrame(topic_word_data)\n",
    "\n",
    "    # Save to CSV\n",
    "    topic_words_filename = os.path.join(results_dir, f\"top{TOP_DIVERSITY_WORDS_N}_reduced_{num_topics_target}_top2vec_words_per_topic_{date_today}.csv\")\n",
    "    df_topic_words.to_csv(topic_words_filename, index=False)\n",
    "    print(f\"Top {TOP_DIVERSITY_WORDS_N} words per topic saved to: {topic_words_filename}\")"
   ],
   "id": "6ea47ff232081336",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize The Reduction Results",
   "id": "363150ad3b7dfdde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../results/20250518_1841_TOP2VEC_reduced/__overall_stats_20250518_1841_TOP2VEC_reduced.csv\")\n",
    "df.info()"
   ],
   "id": "27deedb5df7b67ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Coherence Score Viz",
   "id": "4d498bcd6e285cbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='num_topics', y='coherence_score', data=df)\n",
    "plt.title('Coherence Score vs Number of Topics')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3e393b4f48f37c95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Diversity Score Viz",
   "id": "ffaab88d0669849b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='num_topics', y='diversity_score_top5', data=df, label='Top 5')\n",
    "sns.lineplot(x='num_topics', y='diversity_score_top10', data=df, label='Top 10')\n",
    "sns.lineplot(x='num_topics', y='diversity_score_top20', data=df, label='Top 20')\n",
    "sns.lineplot(x='num_topics', y='diversity_score_top30', data=df, label='Top 30')\n",
    "plt.title('Topic Diversity vs Number of Topics')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Diversity Score')\n",
    "plt.legend(title='Top-N Words')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ae1123962fc985f5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
