{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reduced BERTopic Training",
   "id": "3cfacfcc59825ea5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "from gensim import corpora\n",
    "import logging\n",
    "from src.utils.topic_diversity import topic_diversity\n",
    "from copy import deepcopy\n",
    "from gensim import models\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk_data_path = \"../data/libs/nltk_data\"\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "logging.disable(logging.CRITICAL)\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "9c16dfc3c4418eee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CONFIGURATION FOR SAVING\n",
    "model_name = 'BERTOPIC_reduced'\n",
    "\n",
    "# Get today's date in YYYYMMDD format\n",
    "date_today = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Saved dir path\n",
    "results_dir = f\"../results/{date_today}_{model_name}\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(results_dir, exist_ok=True)# Load Processed Data\n",
    "df = pd.read_csv(\"../data/processed/20250515_1207_minimal_clean_merged_tweets.csv\")\n",
    "\n",
    "df.info()"
   ],
   "id": "317d882f2ecb3b72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load model",
   "id": "c59ef89ff8773006"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "BERTopic_model = BERTopic.load(\"../results/20250531_0008_BERTOPIC/bertopic_model_20250531_0008_30_words\")",
   "id": "282603074fbd7284",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation",
   "id": "8046a30206edad0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TOP_DIVERSITY_WORDS_N = 30\n",
    "TOP_COHERENCE_WORDS_N = 10\n",
    "\n",
    "documents = df['final_text'].astype(str).tolist()\n",
    "tokenized_texts = [str(doc).split() for doc in documents]\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "print(f\"Sampled {len(documents)} documents from full dataset.\")"
   ],
   "id": "ec237d3175b4d8b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Previous best vectorizer for update topic later",
   "id": "eec4b04d26300219"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_embedding_model = 'paraphrase-MiniLM-L12-v2'\n",
    "\n",
    "stopwords_list = set(stopwords.words(\"english\"))\n",
    "custom_stopwords = list(stopwords_list.union({\n",
    "     \"actually\", \"ago\", \"agree\", \"also\", \"answer\", \"anyone\", \"around\", \"article\", \"ask\", \"away\", \"back\", \"bad\", \"bit\", \"could\", \"come\", \"covid\", \"covid-19\", \"covid_19\", \"day\", \"damn\", \"disagree\", \"due\", \"else\", \"ever\", \"everyone\", \"example\", \"finally\", \"find\", \"follow\", \"fuck\", \"get\", \"give\", \"go\", \"good\", \"hah\", \"haha\", \"happen\", \"hear\", \"hell\", \"info\", \"join\", \"kinda\", \"kind\", \"know\", \"later\", \"leave\", \"less\", \"link\", \"live\", \"lol\", \"lolol\", \"long\", \"long-covid\", \"long_covid\", \"longcovid\", \"look\", \"lot\", \"make\", \"many\", \"may\", \"maybe\", \"much\", \"must\", \"need\", \"never\", \"new\", \"next\", \"news\", \"omg\", \"one\", \"ones\", \"people\",  \"ppl\", \"please\", \"post\", \"probably\", \"pretty\", \"quite\", \"read\", \"really\", \"right\", \"say\", \"see\", \"share\", \"shit\", \"show\", \"speak\", \"sorry\", \"sort\", \"sort-of\", \"still\", \"suck\", \"sure\", \"take\", \"talk\", \"tell\", \"thank\", \"thank-you\", \"thanks\", \"think\", \"thing\", \"time\", \"today\", \"try\", \"tweet\", \"twitter\", \"type\", \"uh\", \"uh-huh\", \"um\", \"update\", \"use\", \"vid\", \"via\", \"want\", \"way\", \"well\", \"would\", \"wrong\", \"yeah\", \"yep\",\"even\" ,\"keep\", \"yet\", \"thread\", \"story\", \"watch\", \"listen\", \"write\", \"video\", \"comment\", \"piece\", \"start\", \"stop\", \"let\", \"put\", \"become\", \"seem\", \"great\", \"amazing\", \"interesting\", \"clear\", \"big\", \"huge\", \"point\", \"amp\", \"rt\", \"the\", \"to\", \"is\", \"are\", \"was\", \"were\", \"has\", \"have\", \"had\", \"do\", \"does\", \"did\", \"can\", \"will\", \"just\", \"going\", \"gonna\",  \"covid\", \"long\", \"you\", \"we\", \"your\", \"i\", \"he\", \"she\", \"they\", \"me\", \"us\", \"our\", \"their\", \"my\", \"his\", \"her\", \"them\", \"should\", \"this\", \"that\", \"these\", \"those\", \"some\", \"any\", \"each\", \"other\", \"another\", \"most\", \"something\", \"anything\", \"everything\", \"nothing\", \"way\"\n",
    "}))\n",
    "best_vectorizer = {\"ngram_range\": (1, 2), \"min_df\": 10, \"max_df\": 0.85, \"stop_words\": custom_stopwords}\n",
    "BEST_VECT_ARG = best_vectorizer"
   ],
   "id": "569f92e9f02d9b64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train the reduced model",
   "id": "62c300c511fe1ff5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reduction_range = range(373, 375, 1)\n",
    "original_model = deepcopy(BERTopic_model)\n",
    "\n",
    "for nr_topics in reduction_range:\n",
    "    print(f\"\\nReducing to {nr_topics} topics...\")\n",
    "\n",
    "    try:\n",
    "        # Clone the model and reduce topics\n",
    "        model_reduced = deepcopy(original_model)\n",
    "        model_reduced.reduce_topics(documents, nr_topics=nr_topics)\n",
    "\n",
    "        # Reapply custom vectorizer for clean top words\n",
    "        model_reduced.update_topics(\n",
    "            documents,\n",
    "            vectorizer_model=CountVectorizer(**BEST_VECT_ARG),\n",
    "            top_n_words=TOP_DIVERSITY_WORDS_N\n",
    "        )\n",
    "\n",
    "        topic_info_df = model_reduced.get_topic_info()\n",
    "        topic_labels = topic_info_df.set_index(\"Topic\")[\"Name\"].to_dict()\n",
    "\n",
    "        topic_word_data = []\n",
    "        topic_words_for_coherence = []\n",
    "\n",
    "        # Loop through topics\n",
    "        for topic_id, word_list in model_reduced.get_topics().items():\n",
    "            if topic_id == -1:\n",
    "                continue\n",
    "\n",
    "            topic_label = topic_labels.get(topic_id, f\"Topic {topic_id}\")\n",
    "\n",
    "            # ✅ For diversity export save top 30\n",
    "            for rank, (word, weight) in enumerate(word_list[:TOP_DIVERSITY_WORDS_N], start=1):\n",
    "                topic_word_data.append({\n",
    "                    \"topic\": topic_id,\n",
    "                    \"topic_label\": topic_label,\n",
    "                    \"word_rank\": rank,\n",
    "                    \"word\": word,\n",
    "                    \"weight\": weight\n",
    "                })\n",
    "\n",
    "            # ✅ For coherence split multi-word expressions\n",
    "            top_words = [token for word, _ in word_list[:TOP_COHERENCE_WORDS_N] for token in word.split()]\n",
    "            topic_words_for_coherence.append(top_words)\n",
    "\n",
    "        # Save topic words to CSV\n",
    "        df_words = pd.DataFrame(topic_word_data)\n",
    "        df_words.to_csv(os.path.join(results_dir, f\"reduced_{nr_topics}_topics_top{TOP_DIVERSITY_WORDS_N}_words_{date_today}.csv\"), index=False)\n",
    "        print(f\"Saved topic words for {nr_topics} topics.\")\n",
    "\n",
    "        # Save interactive visualization\n",
    "        vis_path = os.path.join(results_dir, f\"reduced_{nr_topics}_topics_visualization_{date_today}.html\")\n",
    "        model_reduced.visualize_topics().write_html(vis_path)\n",
    "        print(f\"Saved visualization to {vis_path}\")\n",
    "\n",
    "        # Save reduced model\n",
    "        model_path = os.path.join(results_dir, f\"bertopic_model_reduced_{nr_topics}_{date_today}\")\n",
    "        model_reduced.save(model_path)\n",
    "        print(f\"Saved reduced model to {model_path}\")\n",
    "\n",
    "        # Final filter of topic words list\n",
    "        print(f\"Using {len(topic_words_for_coherence)} topics for scoring\")\n",
    "\n",
    "        # Coherence\n",
    "        coherence_model = models.CoherenceModel(\n",
    "            topics=topic_words_for_coherence,\n",
    "            texts=tokenized_texts,\n",
    "            dictionary=dictionary,\n",
    "            coherence='c_v',\n",
    "            topn=TOP_COHERENCE_WORDS_N\n",
    "        )\n",
    "        coherence_score = coherence_model.get_coherence()\n",
    "        print(f\"Coherence (c_v): {coherence_score:.4f}\")\n",
    "\n",
    "        # Diversity\n",
    "        diversity_scores = {}\n",
    "        top_n_values = [5, 10, 20, 30]\n",
    "        for top_n in top_n_values:\n",
    "            div_score = topic_diversity(model_reduced, top_n=top_n, model_type='bertopic')\n",
    "            diversity_scores[f\"diversity_score_top{top_n}\"] = div_score\n",
    "            print(f\"Diversity top-{top_n}: {div_score:.4f}\")\n",
    "\n",
    "        # Save all scores\n",
    "        result = {\n",
    "            \"nr_topics\": nr_topics,\n",
    "            \"coherence_c_v\": coherence_score,\n",
    "            **diversity_scores\n",
    "        }\n",
    "        df_result = pd.DataFrame([result])\n",
    "        df_result.to_csv(os.path.join(results_dir, f\"scores_{nr_topics}_topics_{date_today}.csv\"), index=False)\n",
    "        print(f\"Saved scores for {nr_topics} top  ics.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {nr_topics} topics due to error: {e}\")"
   ],
   "id": "cad1b606400c05fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize The Reduction Results",
   "id": "57c8cea68a7b7aa4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../results/20250531_0008_BERTOPIC_reduced/_overall_reduced_stats_20250531_0008.csv\")\n",
    "df.info()"
   ],
   "id": "4ae00e29ae58e43e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Coherence Score Viz",
   "id": "a0a71851a146e84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='nr_topics', y='coherence_c_v', data=df)\n",
    "plt.title('Coherence Score vs Number of Topics')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f6b2f94fd88f95db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Diversity Score Viz",
   "id": "504d66f0b47eda54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='nr_topics', y='diversity_score_top5', data=df, label='Top 5')\n",
    "sns.lineplot(x='nr_topics', y='diversity_score_top10', data=df, label='Top 10')\n",
    "sns.lineplot(x='nr_topics', y='diversity_score_top20', data=df, label='Top 20')\n",
    "sns.lineplot(x='nr_topics', y='diversity_score_top30', data=df, label='Top 30')\n",
    "plt.title('Topic Diversity vs Number of Topics')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Diversity Score')\n",
    "plt.legend(title='Top-N Words')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a9551ffae2725eab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
