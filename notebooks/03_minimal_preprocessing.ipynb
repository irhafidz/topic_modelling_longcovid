{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Minimal Preprocessing For Top2Vec and BERTopic",
   "id": "9cfb1e4197bb485a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependencies",
   "id": "3d8ec762eae30bd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T05:05:15.176520Z",
     "start_time": "2025-05-15T05:05:14.551956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import emoji\n",
    "import html"
   ],
   "id": "2ff0667d28c94bd6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocess Function",
   "id": "bd041e6b01e65e3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T05:06:12.520443Z",
     "start_time": "2025-05-15T05:06:12.516182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def simple_preprocess(text):\n",
    "    text = text.lower()  # Lowercase for consistency\n",
    "    text = html.unescape(text)  # Convert HTML entities (e.g., &amp; â†’ &)\n",
    "    text = emoji.replace_emoji(text, replace=\"\")  # Remove emojis\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)  # Remove mentions\n",
    "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)  # Convert hashtags to normal words\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize whitespace\n",
    "    return text"
   ],
   "id": "a2935d63843a4744",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Minimal Cleaning Script",
   "id": "8b74d2a52a93235"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T05:07:57.861834Z",
     "start_time": "2025-05-15T05:06:14.013597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/raw/merged_tweets_en.csv')\n",
    "print(f\"Initial rows: {len(df)}\")\n",
    "\n",
    "# Sample for testing (optional)\n",
    "# df = df.sample(100, random_state=41)\n",
    "print(f\"After sampling: {len(df)}\")\n",
    "\n",
    "# Keep relevant columns\n",
    "df = df[[\"date\", \"content\"]]\n",
    "print(f\"After column filtering: {len(df)}\")\n",
    "\n",
    "# Drop missing content\n",
    "df = df.dropna(subset=[\"content\"])\n",
    "print(f\"After dropping missing content: {len(df)}\")\n",
    "\n",
    "# Drop duplicates based on content\n",
    "df = df.drop_duplicates(subset=[\"content\"])\n",
    "print(f\"After dropping duplicates: {len(df)}\")\n",
    "\n",
    "# Apply text preprocessing and directly assign to final_text\n",
    "df[\"final_text\"] = df[\"content\"].apply(simple_preprocess)\n",
    "print(f\"After text preprocessing: {len(df)}\")\n",
    "\n",
    "# Drop empty/blank rows after preprocessing\n",
    "df = df[df[\"final_text\"].str.strip().astype(bool)]\n",
    "print(f\"After removing blank processed_text rows: {len(df)}\")\n",
    "\n",
    "# Save clean data\n",
    "date_today = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "df.to_csv(f\"../data/processed/{date_today}_minimal_clean_merged_tweets.csv\", index=False)\n",
    "\n",
    "# Show preview\n",
    "df.head()"
   ],
   "id": "359e32d780cfd4a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 499123\n",
      "After sampling: 499123\n",
      "After column filtering: 499123\n",
      "After dropping missing content: 499123\n",
      "After dropping duplicates: 497007\n",
      "After text preprocessing: 497007\n",
      "After removing blank processed_text rows: 497007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                        date  \\\n",
       "0  2022-04-29 23:59:28+00:00   \n",
       "1  2022-04-29 23:58:50+00:00   \n",
       "2  2022-04-29 23:58:28+00:00   \n",
       "3  2022-04-29 23:58:22+00:00   \n",
       "4  2022-04-29 23:57:56+00:00   \n",
       "\n",
       "                                             content  \\\n",
       "0  @KunstJonas \"Singing lullabies like 'Twinkle T...   \n",
       "1  Useful, but one of the problems with Long COVI...   \n",
       "2  @AnneMaine3 @Reactively @freemarketrules @Dail...   \n",
       "3  @NSWHealth Dr Moy ( VP AMA)- C19 not done with...   \n",
       "4  @MandateMasksNY @GovKathyHochul @DrMaryTBasset...   \n",
       "\n",
       "                                          final_text  \n",
       "0  \"singing lullabies like 'twinkle twinkle littl...  \n",
       "1  useful, but one of the problems with long covi...  \n",
       "2  i am but i know people with long covid who are...  \n",
       "3  dr moy ( vp ama)- c19 not done with us yet. au...  \n",
       "4  over 4000 cases in fingerlakes region last wee...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-29 23:59:28+00:00</td>\n",
       "      <td>@KunstJonas \"Singing lullabies like 'Twinkle T...</td>\n",
       "      <td>\"singing lullabies like 'twinkle twinkle littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-29 23:58:50+00:00</td>\n",
       "      <td>Useful, but one of the problems with Long COVI...</td>\n",
       "      <td>useful, but one of the problems with long covi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-29 23:58:28+00:00</td>\n",
       "      <td>@AnneMaine3 @Reactively @freemarketrules @Dail...</td>\n",
       "      <td>i am but i know people with long covid who are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-29 23:58:22+00:00</td>\n",
       "      <td>@NSWHealth Dr Moy ( VP AMA)- C19 not done with...</td>\n",
       "      <td>dr moy ( vp ama)- c19 not done with us yet. au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-29 23:57:56+00:00</td>\n",
       "      <td>@MandateMasksNY @GovKathyHochul @DrMaryTBasset...</td>\n",
       "      <td>over 4000 cases in fingerlakes region last wee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
